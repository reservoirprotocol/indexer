# For logging purposes
VERSION=v5

# Port to listen on
PORT=3000

# Chain id the indexer is running on
CHAIN_ID=1

# Required by all admin APIs (via the `X-Admin-Api-Key` header)
ADMIN_API_KEY=MY_KEY

# Http and WebSocket provider URLs
BASE_NETWORK_HTTP_URL=https://eth-mainnet.alchemyapi.io/v2/ALCHEMY_KEY
BASE_NETWORK_WS_URL=wss://eth-mainnet.alchemyapi.io/v2/ALCHEMY_KEY

# Postgres and Redis connection URLs
DATABASE_URL=postgresql://postgres:password@127.0.0.1:5432/postgres?schema=public
DATABASE_DISABLE_STATEMENT_TIMEOUT=0
REDIS_URL=redis://redis:password@127.0.0.1:6379
RATE_LIMIT_REDIS_URL=
REDIS_WEBSOCKET_URL=
METRICS_REDIS_URL=
ORDERSBOOK_REDIS_URL=
ALL_CHAINS_SYNC_REDIS_URL=
REDSHIFT_URL=
ELASTICSEARCH_URL=http://localhost:9200

# Required RabbiqMQ connection
RABBIT_URL=guest:guest@127.0.0.1
RABBIT_HOSTNAME=127.0.0.1
RABBIT_USERNAME=guest
RABBIT_PASSWORD=guest

# If enabled, the indexer will try to catch-up with the tip of the blockchain
CATCHUP=1

# Only one indexer instance should be the master
MASTER=1

# If enabled, the indexer will run any background jobs/processes together with serving API requests
DO_BACKGROUND_WORK=1

DO_WEBSOCKET_WORK=0

DO_WEBSOCKET_SERVER_WORK=0

# If enabled, the indexer will sync data to elasticsearch
DO_ELASTICSEARCH_WORK=1

# If enabled, the workers will process backfill requests
DO_EVENTS_SYNC_BACKFILL=1

# When in the process of backfilling, order handling should be disabled
DISABLE_ORDERS=1

# Disable some processes irrelevant for local testing
LOCAL_TESTING=1

# All of the below envs are optional

# Base URL where all metadata requests should go to (if missing, the indexer will be running in liquidity-only mode)
METADATA_API_BASE_URL=

# Needed for publishing any incoming orders to Arweave
ARWEAVE_RELAYER_KEY=

# For signing TrustUs-style price messages
ORACLE_PRIVATE_KEY=

# For DataDog integration
DATADOG_AGENT_URL=
DATADOG_API_KEY=

# For posting orders to OpenSea
OPENSEA_API_KEY=

# For posting orders to LooksRare
LOOKSRARE_API_KEY=

# For filling/cancelling orders from X2Y2
X2Y2_API_KEY=

ORACLE_AWS_KMS_KEY_ID=
ORACLE_AWS_KMS_KEY_REGION=
FORWARD_OPENSEA_API_KEY=
FORWARD_RESERVOIR_API_KEYS=

AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
FC_AWS_ACCESS_KEY_ID=
FC_AWS_SECRET_ACCESS_KEY=

DATA_EXPORT_AWS_ACCESS_ROLE=
DATA_EXPORT_AWS_S3_UPLOAD_EXTERNAL_ID=
DATA_EXPORT_AWS_S3_UPLOAD_ROLE=
DATA_EXPORT_S3_BUCKET_NAME=
DATA_EXPORT_S3_ARCHIVE_BUCKET_NAME=

MAX_PARALLEL_TOKEN_REFRESH_JOBS=
OPENSEA_INDEXER_API_BASE_URL=
READ_REPLICA_DATABASE_URL=
WRITE_REPLICA_DATABASE_URL=
CIPHER_SECRET=
CB_API_KEY=
SLACK_API_KEY_WEBHOOK_URL=
TRACE_NETWORK_HTTP_URL=
ORDER_FETCHER_API_KEY=
RAILWAY_SNAPSHOT_ID=
BULLMQ_ADMIN_PASSWORD=
METADATA_INDEXING_METHOD=
METADATA_INDEXING_METHOD_COLLECTION=
DISABLE_REALTIME_METADATA_REFRESH=0

# for kafka
DO_KAFKA_WORK=0
KAFKA_PARTITIONS_CONSUMED_CONCURRENTLY=0
KAFKA_CONSUMER_GROUP_ID=
KAFKA_BROKERS=
KAFKA_CLIENT_ID=
KAFKA_MAX_BYTES_PER_PARTITION=1024

# for testing order websocket triggers
DO_OLD_ORDER_WEBSOCKET_WORK=0

OPENSEA_CROSS_POSTING_API_KEY=

BLUR_WS_API_KEY=
BLUR_WS_URL=

MAX_PARALLEL_TOKEN_COLLECTION_SLUG_REFRESH_JOBS=
DO_FT_TRANSFERS_WRITE=0
DO_NFT_TRANSFERS_WRITE=0
DO_PROCESS_BACKFILLING=0
DO_PROCESS_REALTIME=0

# for realtime v2
ENABLE_REALTIME_PROCESSING=0
ENABLE_REALTIME_V2_BLOCK_QUEUE=0

BACKFILL_NETWORK_HTTP_URL=
